{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Transfer learning for EEG\n",
        "\n",
        "This example shows how to train a neural network with supervision on TUH [2]\n",
        "EEG data and transfer the model to NMT [3] EEG dataset. We follow the approach of [1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: MJ Bayazi <mj.darvishi92@gmail.com>\n",
        "#\n",
        "# License: BSD (3-clause)\n",
        "\n",
        "\n",
        "random_state = 2024\n",
        "n_jobs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preprocessing the dataset\n",
        "\n",
        "### Load  and save the raw recordings\n",
        "\n",
        "Here we assume you already load and preprocess the raw recordings for both TUAB and NMT datasetsand saved the file in `TUAB_path' and 'NMT_path' respectively. To read more see this notebook [here](https://braindecode.org/stable/auto_examples/applied_examples/plot_tuh_eeg_corpus.html) \n",
        "\n",
        "### Load the preprocessed data\n",
        "\n",
        "Now, we load a few recordings from the TUAB dataset. Running\n",
        "this example with more recordings should yield better representations and\n",
        "downstream classification performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/conda_envs/braindecode_v3/lib/python3.10/site-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "TUAB_path = '/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/medical/eeg/tuab/tuab_pp3_wzscore_20min'\n",
        "NMT_path = '/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/medical/eeg/NMT/nmt_pp3_wzscore_20min'\n",
        "\n",
        "from braindecode.datautil.serialization import  load_concat_dataset\n",
        "\n",
        "TUAB_ds = load_concat_dataset(TUAB_path, preload=False,\n",
        "                            target_name=['pathological','age','gender'] ,#)\n",
        "                            ids_to_load=range(20)\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target is being set to pathological clf\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(\"target is being set to pathological clf\")\n",
        "target = TUAB_ds.description['pathological'].astype(int)\n",
        "for d, y in zip(TUAB_ds.datasets, target):\n",
        "    d.description['pathological'] = y\n",
        "    d.target_name = 'pathological'\n",
        "    d.target = d.description[d.target_name]\n",
        "TUAB_ds.set_description(pd.DataFrame([d.description for d in TUAB_ds.datasets]), overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting dataset into train, valid and test sets\n",
        "\n",
        "We split the recordings by subject into train, validation and\n",
        "testing sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split based on train split from dataset\n",
        "train_set = TUAB_ds.split('train')['True']\n",
        "test_set = TUAB_ds.split('train')['False']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the model\n",
        "\n",
        "We can now create the deep learning model. In this tutorial, we use DeepNet introduced in [4]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mila/m/mohammad-javad.darvishi-bayasi/projects/bd_4_APD/braindecode/braindecode/models/base.py:23: UserWarning: Deep4Net: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
            "  warnings.warn(\n",
            "/home/mila/m/mohammad-javad.darvishi-bayasi/projects/bd_4_APD/braindecode/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n",
            "/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/conda_envs/braindecode_v3/lib/python3.10/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function to_dense_prediction_model is deprecated; will be removed in version 1.0. Use EEGModuleMixin.to_dense_prediction_model method directly on the model object.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/conda_envs/braindecode_v3/lib/python3.10/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function get_output_shape is deprecated; will be removed in version 1.0. Use EEGModuleMixin.get_output_shape method directly on the model object.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from braindecode.models import Deep4Net\n",
        "\n",
        "n_chans = 21\n",
        "n_classes = 2\n",
        "input_window_samples = 6000\n",
        "drop_prob = 0.5\n",
        "cuda = True # Set to False if you don't have a GPU\n",
        "n_start_chans = 25\n",
        "final_conv_length = 1\n",
        "n_chan_factor = 2\n",
        "stride_before_pool = True\n",
        "# input_window_samples =6000\n",
        "model = Deep4Net(\n",
        "            n_chans, n_classes,\n",
        "            n_filters_time=n_start_chans,\n",
        "            n_filters_spat=n_start_chans,\n",
        "            input_window_samples=input_window_samples,\n",
        "            n_filters_2=int(n_start_chans * n_chan_factor),\n",
        "            n_filters_3=int(n_start_chans * (n_chan_factor ** 2.0)),\n",
        "            n_filters_4=int(n_start_chans * (n_chan_factor ** 3.0)),\n",
        "            final_conv_length=final_conv_length,\n",
        "            stride_before_pool=stride_before_pool,\n",
        "            drop_prob=drop_prob)\n",
        "            # Send model to GPU\n",
        "if cuda:\n",
        "    model.cuda()\n",
        "\n",
        "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
        "\n",
        "to_dense_prediction_model(model)\n",
        "\n",
        "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting windows\n",
        "\n",
        "We extract 60-s windows to be used in both datasets. We use a window size of 6000 samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mila/m/mohammad-javad.darvishi-bayasi/projects/bd_4_APD/braindecode/braindecode/datautil/windowers.py:4: UserWarning: datautil.windowers module is deprecated and is now under preprocessing.windowers, please use from import braindecode.preprocessing.windowers\n",
            "  warn('datautil.windowers module is deprecated and is now under '\n"
          ]
        }
      ],
      "source": [
        "from IPython.utils import io\n",
        "from braindecode.datautil.windowers import create_fixed_length_windows\n",
        "\n",
        "with io.capture_output() as captured:\n",
        "        window_train_set = create_fixed_length_windows(train_set, \n",
        "                                                    start_offset_samples=0,\n",
        "                                                    stop_offset_samples=None,\n",
        "                                                    preload=True,\n",
        "                                                    window_size_samples=input_window_samples,\n",
        "                                                    window_stride_samples=n_preds_per_input,\n",
        "                                                    drop_last_window=True,)\n",
        "        \n",
        "with io.capture_output() as captured:\n",
        "        window_test_set = create_fixed_length_windows(test_set,\n",
        "                                                    start_offset_samples=0,\n",
        "                                                    stop_offset_samples=None,preload=False,\n",
        "                                                    window_size_samples=input_window_samples,\n",
        "                                                    window_stride_samples=n_preds_per_input,\n",
        "                                                    drop_last_window=False,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## defining the classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classifier initialized\n",
            "Number of parameters =  277052\n"
          ]
        }
      ],
      "source": [
        "from braindecode import EEGClassifier\n",
        "from braindecode.training.losses import CroppedLoss\n",
        "import torch\n",
        "from skorch.callbacks import LRScheduler\n",
        "from skorch.helper import predefined_split\n",
        "\n",
        "weight_decay = 0.5 * 0.001\n",
        "lr = 0.0625 * 0.01\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "clf = EEGClassifier(\n",
        "                model,\n",
        "                cropped=True,\n",
        "                classes=[0, 1],\n",
        "                criterion=CroppedLoss,\n",
        "                criterion__loss_function=torch.nn.functional.nll_loss,\n",
        "                optimizer=torch.optim.AdamW,\n",
        "                train_split=predefined_split(window_test_set), \n",
        "                optimizer__lr=lr,\n",
        "                optimizer__weight_decay=weight_decay,\n",
        "                iterator_train__shuffle=True,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[\n",
        "                    \"accuracy\", \"balanced_accuracy\",\"f1\",(\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
        "                    ],\n",
        "                device='cuda' if cuda else 'cpu',\n",
        "                )\n",
        "\n",
        "clf.initialize() # This is important!\n",
        "print('classifier initialized')\n",
        "print(\"Number of parameters = \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n",
        "\n",
        "We can now train our network on the TUAB. We use similar\n",
        "hyperparameters as in [1]_, but reduce the number of epochs and\n",
        "increase the learning rate to account for the smaller setting of\n",
        "this example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing module.\n",
            "Re-initializing criterion because the following parameters were re-set: loss_function.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_accuracy    train_balanced_accuracy    train_f1    train_loss    valid_accuracy    valid_balanced_accuracy    valid_f1    valid_loss      lr     dur\n",
            "-------  ----------------  -------------------------  ----------  ------------  ----------------  -------------------------  ----------  ------------  ------  ------\n",
            "      1            \u001b[36m0.7778\u001b[0m                     \u001b[32m0.5000\u001b[0m      \u001b[35m0.8750\u001b[0m        \u001b[31m0.8197\u001b[0m            \u001b[94m0.5000\u001b[0m                     \u001b[36m0.5000\u001b[0m      \u001b[32m0.6667\u001b[0m        \u001b[35m1.2531\u001b[0m  0.0006  2.2410\n",
            "      2            \u001b[36m0.8333\u001b[0m                     \u001b[32m0.6250\u001b[0m      \u001b[35m0.9032\u001b[0m        \u001b[31m0.5774\u001b[0m            0.5000                     0.5000      0.6667        \u001b[35m1.0273\u001b[0m  0.0006  1.8734\n",
            "      3            \u001b[36m0.9444\u001b[0m                     \u001b[32m0.9643\u001b[0m      \u001b[35m0.9630\u001b[0m        \u001b[31m0.4605\u001b[0m            0.5000                     0.5000      0.6667        \u001b[35m0.7824\u001b[0m  0.0006  1.8630\n",
            "      4            0.8889                     0.9286      0.9231        \u001b[31m0.3513\u001b[0m            0.5000                     0.5000      0.0000        1.0896  0.0005  1.8587\n",
            "      5            0.8333                     0.8929      0.8800        \u001b[31m0.2887\u001b[0m            0.5000                     0.5000      0.0000        1.5666  0.0004  1.8595\n",
            "      6            0.7778                     0.8571      0.8333        \u001b[31m0.2490\u001b[0m            0.5000                     0.5000      0.0000        1.8134  0.0003  1.9343\n",
            "      7            0.6111                     0.7500      0.6667        \u001b[31m0.2348\u001b[0m            0.5000                     0.5000      0.0000        1.9306  0.0002  1.9427\n",
            "      8            0.6667                     0.7857      0.7273        \u001b[31m0.2140\u001b[0m            0.5000                     0.5000      0.0000        1.9725  0.0001  1.9675\n",
            "      9            0.7778                     0.8571      0.8333        \u001b[31m0.2091\u001b[0m            0.5000                     0.5000      0.0000        1.9632  0.0000  1.9312\n",
            "     10            0.7778                     0.8571      0.8333        0.2127            0.5000                     0.5000      0.0000        1.9504  0.0000  1.9296\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=============================================================================================================================================\n",
              "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
              "  ============================================================================================================================================\n",
              "  Deep4Net (Deep4Net)                      [1, 21, 6000]             [1, 2, 5794]              --                        --\n",
              "  ├─Ensure4d (ensuredims): 1-1             [1, 21, 6000]             [1, 21, 6000, 1]          --                        --\n",
              "  ├─Rearrange (dimshuffle): 1-2            [1, 21, 6000, 1]          [1, 1, 6000, 21]          --                        --\n",
              "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 21]          [1, 25, 5991, 1]          13,400                    --\n",
              "  ├─BatchNorm2d (bnorm): 1-4               [1, 25, 5991, 1]          [1, 25, 5991, 1]          50                        --\n",
              "  ├─Expression (conv_nonlin): 1-5          [1, 25, 5991, 1]          [1, 25, 5991, 1]          --                        --\n",
              "  ├─MaxPool2d (pool): 1-6                  [1, 25, 5991, 1]          [1, 25, 5989, 1]          --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin): 1-7          [1, 25, 5989, 1]          [1, 25, 5989, 1]          --                        --\n",
              "  ├─Dropout (drop_2): 1-8                  [1, 25, 5989, 1]          [1, 25, 5989, 1]          --                        --\n",
              "  ├─Conv2d (conv_2): 1-9                   [1, 25, 5989, 1]          [1, 50, 5980, 1]          12,500                    [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 50, 5980, 1]          [1, 50, 5980, 1]          100                       --\n",
              "  ├─Expression (nonlin_2): 1-11            [1, 50, 5980, 1]          [1, 50, 5980, 1]          --                        --\n",
              "  ├─MaxPool2d (pool_2): 1-12               [1, 50, 5980, 1]          [1, 50, 5974, 1]          --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_2): 1-13       [1, 50, 5974, 1]          [1, 50, 5974, 1]          --                        --\n",
              "  ├─Dropout (drop_3): 1-14                 [1, 50, 5974, 1]          [1, 50, 5974, 1]          --                        --\n",
              "  ├─Conv2d (conv_3): 1-15                  [1, 50, 5974, 1]          [1, 100, 5947, 1]         50,000                    [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 100, 5947, 1]         [1, 100, 5947, 1]         200                       --\n",
              "  ├─Expression (nonlin_3): 1-17            [1, 100, 5947, 1]         [1, 100, 5947, 1]         --                        --\n",
              "  ├─MaxPool2d (pool_3): 1-18               [1, 100, 5947, 1]         [1, 100, 5929, 1]         --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_3): 1-19       [1, 100, 5929, 1]         [1, 100, 5929, 1]         --                        --\n",
              "  ├─Dropout (drop_4): 1-20                 [1, 100, 5929, 1]         [1, 100, 5929, 1]         --                        --\n",
              "  ├─Conv2d (conv_4): 1-21                  [1, 100, 5929, 1]         [1, 200, 5848, 1]         200,000                   [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 200, 5848, 1]         [1, 200, 5848, 1]         400                       --\n",
              "  ├─Expression (nonlin_4): 1-23            [1, 200, 5848, 1]         [1, 200, 5848, 1]         --                        --\n",
              "  ├─MaxPool2d (pool_4): 1-24               [1, 200, 5848, 1]         [1, 200, 5794, 1]         --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_4): 1-25       [1, 200, 5794, 1]         [1, 200, 5794, 1]         --                        --\n",
              "  ├─Sequential (final_layer): 1-26         [1, 200, 5794, 1]         [1, 2, 5794]              --                        --\n",
              "  │    └─Conv2d (conv_classifier): 2-1     [1, 200, 5794, 1]         [1, 2, 5794, 1]           402                       [1, 1]\n",
              "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 5794, 1]           [1, 2, 5794, 1]           --                        --\n",
              "  │    └─Expression (squeeze): 2-3         [1, 2, 5794, 1]           [1, 2, 5794]              --                        --\n",
              "  ============================================================================================================================================\n",
              "  Total params: 277,052\n",
              "  Trainable params: 277,052\n",
              "  Non-trainable params: 0\n",
              "  Total mult-adds (G): 1.54\n",
              "  ============================================================================================================================================\n",
              "  Input size (MB): 0.50\n",
              "  Forward/backward pass size (MB): 34.30\n",
              "  Params size (MB): 1.05\n",
              "  Estimated Total Size (MB): 35.86\n",
              "  ============================================================================================================================================,\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(window_train_set, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_path = '/home/mila/m/mohammad-javad.darvishi-bayasi/scratch/medical/eeg/tuab/results/'\n",
        "path = result_path + \"model_{}.pt\".format(random_state)\n",
        "torch.save(clf.module, path)\n",
        "path = result_path + \"state_dict_{}.pt\".format(random_state)\n",
        "torch.save(clf.module.state_dict(), path)\n",
        "\n",
        "clf.save_params(f_params=result_path +'model.pkl', f_optimizer= result_path +'opt.pkl', f_history=result_path +'history.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load NMT dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mne\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "NMT_ds = load_concat_dataset(NMT_path, preload=False,\n",
        "                            target_name=['pathological','age','gender'] ,#)\n",
        "                            ids_to_load=range(200)\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split based on train split from dataset\n",
        "train_set = NMT_ds.split('train')['True']\n",
        "test_set = NMT_ds.split('train')['False']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "target is being set to pathological clf\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "print(\"target is being set to pathological clf\")\n",
        "target = NMT_ds.description['pathological'].astype(int)\n",
        "for d, y in zip(NMT_ds.datasets, target):\n",
        "    d.description['pathological'] = y\n",
        "    d.target_name = 'pathological'\n",
        "    d.target = d.description[d.target_name]\n",
        "NMT_ds.set_description(pd.DataFrame([d.description for d in NMT_ds.datasets]), overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### extracting windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.utils import io\n",
        "from braindecode.datautil.windowers import create_fixed_length_windows\n",
        "\n",
        "with io.capture_output() as captured:\n",
        "        window_train_set = create_fixed_length_windows(train_set, \n",
        "                                                    start_offset_samples=0,\n",
        "                                                    stop_offset_samples=None,\n",
        "                                                    preload=True,\n",
        "                                                    window_size_samples=input_window_samples,\n",
        "                                                    window_stride_samples=n_preds_per_input,\n",
        "                                                    drop_last_window=True,)\n",
        "with io.capture_output() as captured:\n",
        "        window_test_set = create_fixed_length_windows(test_set,\n",
        "                                                    start_offset_samples=0,\n",
        "                                                    stop_offset_samples=None,preload=False,\n",
        "                                                    window_size_samples=input_window_samples,\n",
        "                                                    window_stride_samples=n_preds_per_input,\n",
        "                                                    drop_last_window=False,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## loading the pre trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pre-trained model loaded using pytorch\n"
          ]
        }
      ],
      "source": [
        "load_path = result_path + 'state_dict_2024.pt'\n",
        "state_dicts = torch.load(load_path) \n",
        "model.load_state_dict(state_dicts, strict= False)\n",
        "print('pre-trained model loaded using pytorch')\n",
        "\n",
        "## freeze layers ##\n",
        "freez = False\n",
        "if freez:\n",
        "    for ii, (name, param) in enumerate(model.named_parameters()):\n",
        "        # if 'temporal_block_0' in name or 'temporal_block_1' in name or 'temporal_block_2' in name or 'temporal_block_3' in name: # or 'temporal_block_5' in name or 'conv_classifier' in name:\n",
        "        if not 'conv_classifier' in name:\n",
        "            param.requires_grad = False\n",
        "            print('param:', name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## fine tuning the model on NMT dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "classifier initialized\n",
            "Number of parameters =  277052\n"
          ]
        }
      ],
      "source": [
        "from braindecode import EEGClassifier\n",
        "from braindecode.training.losses import CroppedLoss\n",
        "import torch\n",
        "from skorch.callbacks import LRScheduler\n",
        "from skorch.helper import predefined_split\n",
        "\n",
        "weight_decay = 0.5 * 0.001\n",
        "lr = 0.0625 * 0.01\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "clf = EEGClassifier(\n",
        "                model,\n",
        "                cropped=True,\n",
        "                classes=[0, 1],\n",
        "                criterion=CroppedLoss,\n",
        "                criterion__loss_function=torch.nn.functional.nll_loss,\n",
        "                optimizer=torch.optim.AdamW,\n",
        "                train_split=predefined_split(window_test_set), \n",
        "                optimizer__lr=lr,\n",
        "                optimizer__weight_decay=weight_decay,\n",
        "                iterator_train__shuffle=True,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[\n",
        "                    \"accuracy\", \"balanced_accuracy\",\"f1\",(\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
        "                    ],\n",
        "                device='cuda' if cuda else 'cpu',\n",
        "                )\n",
        "\n",
        "clf.initialize() # This is important!\n",
        "print('classifier initialized')\n",
        "print(\"Number of parameters = \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Re-initializing module.\n",
            "Re-initializing criterion because the following parameters were re-set: loss_function.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_accuracy    train_balanced_accuracy    train_f1    train_loss    valid_accuracy    valid_balanced_accuracy    valid_f1    valid_loss      lr      dur\n",
            "-------  ----------------  -------------------------  ----------  ------------  ----------------  -------------------------  ----------  ------------  ------  -------\n",
            "      1            \u001b[36m0.8287\u001b[0m                     \u001b[32m0.5000\u001b[0m      \u001b[35m0.0000\u001b[0m        \u001b[31m0.7474\u001b[0m            \u001b[94m0.5263\u001b[0m                     \u001b[36m0.5000\u001b[0m      \u001b[32m0.0000\u001b[0m        \u001b[35m1.1033\u001b[0m  0.0006  11.4481\n",
            "      2            0.7348                     \u001b[32m0.7376\u001b[0m      \u001b[35m0.4894\u001b[0m        \u001b[31m0.4602\u001b[0m            \u001b[94m0.7895\u001b[0m                     \u001b[36m0.8000\u001b[0m      \u001b[32m0.8182\u001b[0m        \u001b[35m0.5255\u001b[0m  0.0006  11.3550\n",
            "      3            0.7956                     \u001b[32m0.7615\u001b[0m      \u001b[35m0.5432\u001b[0m        \u001b[31m0.4352\u001b[0m            0.7895                     0.7889      0.7778        \u001b[35m0.5083\u001b[0m  0.0006  10.9772\n",
            "      4            \u001b[36m0.8508\u001b[0m                     \u001b[32m0.8460\u001b[0m      \u001b[35m0.6582\u001b[0m        \u001b[31m0.4103\u001b[0m            0.6842                     0.6833      0.6667        0.5383  0.0005  10.9550\n",
            "      5            0.8011                     0.8416      0.6087        \u001b[31m0.3891\u001b[0m            0.7368                     0.7444      0.7619        0.5412  0.0004  11.1675\n",
            "      6            \u001b[36m0.8619\u001b[0m                     \u001b[32m0.8783\u001b[0m      \u001b[35m0.6914\u001b[0m        \u001b[31m0.3758\u001b[0m            0.7895                     0.7944      0.8000        \u001b[35m0.5022\u001b[0m  0.0003  11.7050\n",
            "      7            \u001b[36m0.8729\u001b[0m                     0.8722      \u001b[35m0.7013\u001b[0m        \u001b[31m0.3641\u001b[0m            0.7368                     0.7389      0.7368        0.5171  0.0002  10.8927\n",
            "      8            \u001b[36m0.8785\u001b[0m                     0.8755      \u001b[35m0.7105\u001b[0m        \u001b[31m0.3578\u001b[0m            0.6316                     0.6278      0.5882        0.5448  0.0001  10.8997\n",
            "      9            0.8785                     0.8755      0.7105        \u001b[31m0.3542\u001b[0m            0.6316                     0.6278      0.5882        0.5343  0.0000  10.8798\n",
            "     10            0.8785                     0.8755      0.7105        \u001b[31m0.3521\u001b[0m            0.6316                     0.6278      0.5882        0.5363  0.0000  10.8942\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=============================================================================================================================================\n",
              "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
              "  ============================================================================================================================================\n",
              "  Deep4Net (Deep4Net)                      [1, 21, 6000]             [1, 2, 5794]              --                        --\n",
              "  ├─Ensure4d (ensuredims): 1-1             [1, 21, 6000]             [1, 21, 6000, 1]          --                        --\n",
              "  ├─Rearrange (dimshuffle): 1-2            [1, 21, 6000, 1]          [1, 1, 6000, 21]          --                        --\n",
              "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 6000, 21]          [1, 25, 5991, 1]          13,400                    --\n",
              "  ├─BatchNorm2d (bnorm): 1-4               [1, 25, 5991, 1]          [1, 25, 5991, 1]          50                        --\n",
              "  ├─Expression (conv_nonlin): 1-5          [1, 25, 5991, 1]          [1, 25, 5991, 1]          --                        --\n",
              "  ├─MaxPool2d (pool): 1-6                  [1, 25, 5991, 1]          [1, 25, 5989, 1]          --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin): 1-7          [1, 25, 5989, 1]          [1, 25, 5989, 1]          --                        --\n",
              "  ├─Dropout (drop_2): 1-8                  [1, 25, 5989, 1]          [1, 25, 5989, 1]          --                        --\n",
              "  ├─Conv2d (conv_2): 1-9                   [1, 25, 5989, 1]          [1, 50, 5980, 1]          12,500                    [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_2): 1-10            [1, 50, 5980, 1]          [1, 50, 5980, 1]          100                       --\n",
              "  ├─Expression (nonlin_2): 1-11            [1, 50, 5980, 1]          [1, 50, 5980, 1]          --                        --\n",
              "  ├─MaxPool2d (pool_2): 1-12               [1, 50, 5980, 1]          [1, 50, 5974, 1]          --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_2): 1-13       [1, 50, 5974, 1]          [1, 50, 5974, 1]          --                        --\n",
              "  ├─Dropout (drop_3): 1-14                 [1, 50, 5974, 1]          [1, 50, 5974, 1]          --                        --\n",
              "  ├─Conv2d (conv_3): 1-15                  [1, 50, 5974, 1]          [1, 100, 5947, 1]         50,000                    [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_3): 1-16            [1, 100, 5947, 1]         [1, 100, 5947, 1]         200                       --\n",
              "  ├─Expression (nonlin_3): 1-17            [1, 100, 5947, 1]         [1, 100, 5947, 1]         --                        --\n",
              "  ├─MaxPool2d (pool_3): 1-18               [1, 100, 5947, 1]         [1, 100, 5929, 1]         --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_3): 1-19       [1, 100, 5929, 1]         [1, 100, 5929, 1]         --                        --\n",
              "  ├─Dropout (drop_4): 1-20                 [1, 100, 5929, 1]         [1, 100, 5929, 1]         --                        --\n",
              "  ├─Conv2d (conv_4): 1-21                  [1, 100, 5929, 1]         [1, 200, 5848, 1]         200,000                   [10, 1]\n",
              "  ├─BatchNorm2d (bnorm_4): 1-22            [1, 200, 5848, 1]         [1, 200, 5848, 1]         400                       --\n",
              "  ├─Expression (nonlin_4): 1-23            [1, 200, 5848, 1]         [1, 200, 5848, 1]         --                        --\n",
              "  ├─MaxPool2d (pool_4): 1-24               [1, 200, 5848, 1]         [1, 200, 5794, 1]         --                        [3, 1]\n",
              "  ├─Expression (pool_nonlin_4): 1-25       [1, 200, 5794, 1]         [1, 200, 5794, 1]         --                        --\n",
              "  ├─Sequential (final_layer): 1-26         [1, 200, 5794, 1]         [1, 2, 5794]              --                        --\n",
              "  │    └─Conv2d (conv_classifier): 2-1     [1, 200, 5794, 1]         [1, 2, 5794, 1]           402                       [1, 1]\n",
              "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 5794, 1]           [1, 2, 5794, 1]           --                        --\n",
              "  │    └─Expression (squeeze): 2-3         [1, 2, 5794, 1]           [1, 2, 5794]              --                        --\n",
              "  ============================================================================================================================================\n",
              "  Total params: 277,052\n",
              "  Trainable params: 277,052\n",
              "  Non-trainable params: 0\n",
              "  Total mult-adds (G): 1.54\n",
              "  ============================================================================================================================================\n",
              "  Input size (MB): 0.50\n",
              "  Forward/backward pass size (MB): 34.30\n",
              "  Params size (MB): 1.05\n",
              "  Estimated Total Size (MB): 35.86\n",
              "  ============================================================================================================================================,\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(window_train_set, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this example, we used transfer learning (TL) as a way to learn\n",
        "representations from a large EEG data and transfer to a smaller dataset. \n",
        "\n",
        "\n",
        "## References\n",
        "\n",
        ".. [1] Darvishi-Bayazi, M. J., Ghaemi, M. S., Lesort, T., Arefin, M. R., Faubert, J., & Rish, I. (2024). Amplifying pathological detection in EEG signaling pathways through cross-dataset transfer learning. Computers in Biology and Medicine, 169, 107893.\n",
        "\n",
        ".. [2] Shawki, N., Shadin, M. G., Elseify, T., Jakielaszek, L., Farkas, T., Persidsky, Y., ... & Picone, J. (2022). Correction to: The temple university hospital digital pathology corpus. In Signal Processing in Medicine and Biology: Emerging Trends in Research and Applications (pp. C1-C1). Cham: Springer International Publishing..\n",
        "\n",
        ".. [3] Khan, H. A., Ul Ain, R., Kamboh, A. M., & Butt, H. T. (2022). The NMT scalp EEG dataset: an open-source annotated dataset of healthy and pathological EEG recordings for predictive modeling. Frontiers in neuroscience, 15, 755817.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
